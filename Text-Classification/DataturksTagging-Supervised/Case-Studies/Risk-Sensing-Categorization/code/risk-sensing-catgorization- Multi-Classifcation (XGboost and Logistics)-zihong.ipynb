{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is the codebook about labelled multi-classification.  \n",
    "The methods we used: Logistics, XGboost, new feature(word count) and oversample.      \n",
    "Finally, the logitics without word count perform best, which obtain acc 0.63.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**multi-classfication  \n",
    "wordcount+logistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep2 = pd.read_csv('df_prep2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "df_prep2['word_count'] = [len(item.split(\" \")) for item in df_prep2['contents']]\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(df_prep2.contents,df_prep2['risk_cat'],\n",
    "                                                                    test_size = 0.2, random_state = 42) \n",
    "\n",
    "y_train = y_train.replace(['Macro Environment', 'Product Availability', 'Not Risk',\n",
    "       'Industry Adjacent', 'Invalid', 'Product Failure',\n",
    "       'Service Failure/Availability', 'Others',\n",
    "       'Changes in Company Policy', 'Employee Misconduct',\n",
    "       'Customer Misconduct', 'Confrontation'],[0,1,2,3,4,5,6,7,8,9,10,11])\n",
    "y_test = y_test.replace(['Macro Environment', 'Product Availability', 'Not Risk',\n",
    "       'Industry Adjacent', 'Invalid', 'Product Failure',\n",
    "       'Service Failure/Availability', 'Others',\n",
    "       'Changes in Company Policy', 'Employee Misconduct',\n",
    "       'Customer Misconduct', 'Confrontation'],[0,1,2,3,4,5,6,7,8,9,10,11])\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "y_train['risk_cat'] = y_train['risk_cat'].astype('int')\n",
    "y_test['risk_cat'] = y_test['risk_cat'].astype('int')\n",
    "\n",
    "tfidf1 = TfidfVectorizer() \n",
    "tfidf1.fit(x_train)  \n",
    "x_train= tfidf1.transform(x_train) \n",
    "x_test = tfidf1.transform(x_test) \n",
    "x_train_wc =  hstack([x_train,np.array([df_prep2.iloc[y_train.index.values]['word_count']]).T])\n",
    "x_test_wc =  hstack([x_test,np.array([df_prep2.iloc[y_test.index.values]['word_count']]).T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\E055761\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.41165234001910217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        39\n",
      "           1       0.00      0.00      0.00        66\n",
      "           2       0.43      0.83      0.56       244\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        26\n",
      "           5       0.00      0.00      0.00        45\n",
      "           6       0.43      0.63      0.51       124\n",
      "           7       0.32      0.61      0.42       176\n",
      "           8       0.00      0.00      0.00        97\n",
      "           9       0.79      0.28      0.41       157\n",
      "          10       0.00      0.00      0.00        21\n",
      "          11       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.41      1047\n",
      "   macro avg       0.16      0.20      0.16      1047\n",
      "weighted avg       0.32      0.41      0.32      1047\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\E055761\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\E055761\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lr1 = LogisticRegression(multi_class='multinomial',random_state=123,penalty='l2', solver='lbfgs')\n",
    "lr1.fit(x_train_wc, y_train)\n",
    "y_pred_log = lr1.predict_proba(x_test_wc)\n",
    "\n",
    "import numpy as np\n",
    "y_pred_log = [np.argmax(line) for line in y_pred_log]\n",
    "print('accuracy %s' % accuracy_score(y_pred_log, y_test))\n",
    "print(classification_report(y_test, y_pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**multi-classification  \n",
    "wordcount+xgb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:54:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy 0.6074498567335244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.23      0.34        39\n",
      "           1       0.64      0.56      0.60        66\n",
      "           2       0.57      0.76      0.65       244\n",
      "           3       0.75      0.20      0.32        30\n",
      "           4       0.21      0.15      0.18        26\n",
      "           5       0.93      0.93      0.93        45\n",
      "           6       0.66      0.60      0.63       124\n",
      "           7       0.52      0.63      0.57       176\n",
      "           8       0.74      0.55      0.63        97\n",
      "           9       0.64      0.62      0.63       157\n",
      "          10       0.91      0.48      0.62        21\n",
      "          11       0.35      0.27      0.31        22\n",
      "\n",
      "    accuracy                           0.61      1047\n",
      "   macro avg       0.63      0.50      0.53      1047\n",
      "weighted avg       0.62      0.61      0.60      1047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(data=x_train, label=y_train)\n",
    "dtest = xgb.DMatrix(data=x_test)\n",
    "dtest = xgb.DMatrix(data=x_test)\n",
    "param = {\n",
    "    'max_depth': 6,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 12}  # the number of classes that exist in this datset\n",
    "num_round = 20  # the number of training iterations\n",
    "xg1 = xgb.train(param, dtrain, num_round)\n",
    "pred1 = xg1.predict(dtest)\n",
    "pred1 = [np.argmax(line) for line in pred1]\n",
    "print('accuracy %s' % accuracy_score(pred1, y_test))\n",
    "print(classification_report(y_test, pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**multi-classification  \n",
    "without word count + logistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.626552053486151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.33      0.47        39\n",
      "           1       0.73      0.58      0.64        66\n",
      "           2       0.55      0.80      0.65       244\n",
      "           3       0.50      0.17      0.25        30\n",
      "           4       1.00      0.08      0.14        26\n",
      "           5       0.93      0.84      0.88        45\n",
      "           6       0.68      0.65      0.66       124\n",
      "           7       0.54      0.66      0.59       176\n",
      "           8       0.76      0.60      0.67        97\n",
      "           9       0.65      0.64      0.64       157\n",
      "          10       1.00      0.48      0.65        21\n",
      "          11       1.00      0.09      0.17        22\n",
      "\n",
      "    accuracy                           0.63      1047\n",
      "   macro avg       0.76      0.49      0.54      1047\n",
      "weighted avg       0.66      0.63      0.61      1047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#without wordcount\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(df_prep2.contents,df_prep2['risk_cat'],\n",
    "                                                                    test_size = 0.2, random_state = 42) \n",
    "y_train = y_train.replace(['Macro Environment', 'Product Availability', 'Not Risk',\n",
    "       'Industry Adjacent', 'Invalid', 'Product Failure',\n",
    "       'Service Failure/Availability', 'Others',\n",
    "       'Changes in Company Policy', 'Employee Misconduct',\n",
    "       'Customer Misconduct', 'Confrontation'],[0,1,2,3,4,5,6,7,8,9,10,11])\n",
    "y_test = y_test.replace(['Macro Environment', 'Product Availability', 'Not Risk',\n",
    "       'Industry Adjacent', 'Invalid', 'Product Failure',\n",
    "       'Service Failure/Availability', 'Others',\n",
    "       'Changes in Company Policy', 'Employee Misconduct',\n",
    "       'Customer Misconduct', 'Confrontation'],[0,1,2,3,4,5,6,7,8,9,10,11])\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "y_train['risk_cat'] = y_train['risk_cat'].astype('int')\n",
    "y_test['risk_cat'] = y_test['risk_cat'].astype('int')\n",
    "\n",
    "tfidf1 = TfidfVectorizer() \n",
    "tfidf1.fit(x_train)  \n",
    "x_train= tfidf1.transform(x_train) \n",
    "x_test = tfidf1.transform(x_test) \n",
    "\n",
    "\n",
    "lr1 = LogisticRegression(multi_class='multinomial',random_state=123,penalty='l2', solver='lbfgs')\n",
    "lr1.fit(x_train, y_train)\n",
    "y_pred_log = lr1.predict_proba(x_test)\n",
    "\n",
    "\n",
    "y_pred_log = [np.argmax(line) for line in y_pred_log]\n",
    "print('accuracy %s' % accuracy_score(y_pred_log, y_test))\n",
    "print(classification_report(y_test, y_pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**multi-classification  \n",
    "without word count + xgb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:34:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy 0.5959885386819485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.18      0.27        39\n",
      "           1       0.61      0.55      0.58        66\n",
      "           2       0.57      0.75      0.65       244\n",
      "           3       0.60      0.20      0.30        30\n",
      "           4       0.12      0.08      0.10        26\n",
      "           5       0.91      0.93      0.92        45\n",
      "           6       0.63      0.62      0.62       124\n",
      "           7       0.50      0.62      0.55       176\n",
      "           8       0.77      0.55      0.64        97\n",
      "           9       0.64      0.59      0.61       157\n",
      "          10       1.00      0.48      0.65        21\n",
      "          11       0.33      0.23      0.27        22\n",
      "\n",
      "    accuracy                           0.60      1047\n",
      "   macro avg       0.60      0.48      0.51      1047\n",
      "weighted avg       0.60      0.60      0.59      1047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(data=x_train, label=y_train)\n",
    "dtest = xgb.DMatrix(data=x_test)\n",
    "dtest = xgb.DMatrix(data=x_test)\n",
    "param = {\n",
    "    'max_depth': 6,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 12}  # the number of classes that exist in this datset\n",
    "num_round = 20  # the number of training iterations\n",
    "xg1 = xgb.train(param, dtrain, num_round)\n",
    "pred1 = xg1.predict(dtest)\n",
    "pred1 = [np.argmax(line) for line in pred1]\n",
    "print('accuracy %s' % accuracy_score(pred1, y_test))\n",
    "print(classification_report(y_test, pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
